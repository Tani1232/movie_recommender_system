import numpy as np
import pandas as pd
data = pd.read_csv('imdb.csv')
new = data.iloc[:,2:8]
new = new.dropna()
new['genre'] = new['genre'].str.replace(r',\s*', ',', regex=True)
new['cast'] = new['cast'].str.replace(r'\b\s+', '', regex=True)
new['tags'] = new['overview']+new['genre']+','+new['director']+','+new['cast']
newo = new.copy()
new = new.drop(['genre'],axis=1)
new = new.drop(['overview'],axis=1)
new = new.drop(['director'],axis=1)
new = new.drop(['cast'],axis=1)
new['tags'] = new['tags'].apply(lambda x:x.lower())
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features=5000,stop_words='english')
vectors = cv.fit_transform(new['tags']).toarray()
cv.get_feature_names_out()
import nltk
from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()
def stem(text):
    y = []
    for i in text.split():
        y.append(ps.stem(i))
    return " ".join(y)
new['tags'] = new['tags'].apply(stem)
from sklearn.metrics.pairwise import cosine_similarity
similarity = cosine_similarity(vectors)
sorted(list(enumerate(similarity[0])),reverse=True,key=lambda x:x[1])[1:6]
def recommend(movie):
    movie_index = new[new['movie_name'] == movie].index[0]
    distances = similarity[movie_index]
    movies_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:6]


    for i in movies_list:
        print(new.iloc[i[0]].movie_name)
import pickle

# Save the vectorizer (CountVectorizer or TfidfVectorizer)
with open('vectorizer.pkl', 'wb') as f:
    pickle.dump(cv, f)  # Replace 'cv' with your vectorizer variable

# Save the vectors
with open('vectors.pkl', 'wb') as f:
    pickle.dump(vectors, f)

# Save the similarity matrix
with open('similarity.pkl', 'wb') as f:
    pickle.dump(similarity, f)

# Save the cleaned movie dataset used in Flask (including movie_name and index)
newo[['movie_name', 'genre', 'cast', 'director', 'tags']].to_csv('imdb.csv', index=False)
